{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ST499: Modelling question quality across multiple disciplines\n",
    "\n",
    "## LSE\n",
    "\n",
    "### Brad Carruthers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Opinion dynamics\n",
    "\n",
    "Javarone2014 finds that conformity has a strong role in opinion dynamics and that conformists are stabilisers in fully-connected networks.\n",
    "\n",
    "Das2014 estimate conformity values using the social graph and expressed opinions, and use estimated conformity values to explore \"seed recovery\" which is the identification of the smallest subset of users that eventually dictate the entire social graph's opinions having been seeded non-neutral opinions. They say (quite scarily) that solving these problems is crucial to efficiently sample innate user opinions, seed opinions to maximize opinion adoption and identify prime candidates for viral marketing.\n",
    "\n",
    "Zhu2017 look at network vector autoregression which aims to investigate the time series dynamic of responses from different nodes in a network.\n",
    "\n",
    "Abebe2018 look at interventions that modify the susceptability to persuasion of individuals, which sounds very similar if not the same as conformity bias. In their experimental findings they find that their proposed framework outperforms baselines and is able to achieve a multi-fold effect on the network's total sum of opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matchbox: Large Scale Online Bayesian Recommendations\n",
    "\n",
    "Stern2009 develop a probabilistic model for generating personalised item recommendations to users of a specific web service. The Matchbox system uses user and item meta data as well as collaborative filtering information from the user's previous behaviour to predict the value of an item for a user. Users/items are represented as feature vectors and are mapped into a low-dimensional \"trait-space\" to measure the similarity with inner products. \n",
    "\n",
    "Problem is, this eliminates helping new questioners on SE, which arguable need the most guidance and attention. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Matching for Expert Systems with Uncertain Task Types\n",
    "\n",
    "Shah2018 discuss matching in a two-sided market to address the externality that arises out of the matched resource becoming unavailable, even temporarilly. This is particularly an issue in online platforms with human expertise. Efficient matching in these platforms is also more difficult owing to the fact that party information is usually limited. \n",
    "\n",
    "In order to address this, a model is developed to incorporate feedback from past matches over and above prior information on the task. This model has tasks arriving online where experts are fixed and constrained by a finite service capacity. They characterise the maximum task completion throughput that is achievable.\n",
    "\n",
    "The greedy approach whereby experts are assigned tasks most suitable to their skill is suboptimal, since it does not take into account the aforementioned externality. A throughput optimal backpressure algorithm is constructed which does this by accounting for 'congestion' over different task types.\n",
    "\n",
    "\"For instance in a Q&A scenario, a question which an expert in Calculus failed to answer either is not about Calculus, or is very hard\" - what if it is about calculus, isn't hard but there was not enough information to ascertain the task type (someone didn't know how to express their misconception)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Crowdsourcing to Graphon Estimation, Statistically\n",
    "\n",
    "Shah2018 states that the canonical question for micro-task crowdsourcing or aggregating opinions in general is finding the correct answers to binary tasks from multiple noisy answers in an unsupervised manner.\n",
    "\n",
    "Graphon estimation concerns estimating edge intensities or probabilities between nodes using a single snapshot of a graph in time.\n",
    "\n",
    "For crowdsourcing, the key issue is understanding whether a task is able to be more accurately denoised by aggregating answers collected from various other tasks.\n",
    "\n",
    "Using concepts from graphon estimation, they create an algorithm which achieves better performance than majority voting for a setup which goes beyond the rank one models considered in previous literature. We use known lower bounds for crowdsourcing to derive lower bounds for graphon estimation.\n",
    "\n",
    "They use the known crowdsourcing lower bounds in order to derive graphon estimation lower bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StackExchange\n",
    "\n",
    "Posnett2012 find that despite the hypotheses of the incentive structure of SE suggest quality of answers improve over time and that participants in the community should experience improved answers over time are incorrect. They also find that participants tenure in the community is not linked to the quality of their answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Analytics Application\n",
    "\n",
    "Brinton2014 identify and address two main issues on Massive Open Online Courses - high decline rate and information overload.\n",
    "\n",
    "Regarding the information overload, they propose a unified generative model for discussing threads, allowing them to choose efficient thread classifiers as well as design an effective algorithm to rank relevance.\n",
    "\n",
    "Their methodology for addressing information overload:\n",
    "\n",
    "* First few days see a lot of small-talk in forums which need to be classified and filtered out\n",
    "* Small talk then fades away, thus need to rank relevance of new threads over time\n",
    "\n",
    "Therefore need effective classifier for discussion-thread and algorithm for ranking relevance.\n",
    "\n",
    "Here is their methodology:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion quality in the digital public square\n",
    "\n",
    "Berry2017 found that ranking Facebook comments by quality rather than temporally lead to higher discussion quality.\n",
    "\n",
    "* They lay groundwork for studying comment-quality and show that text-only models can predict and measure quality.\n",
    "* They evaluate methods to rank the dimension of quality depicted to users and show how depicted higher quality comments can improve user experience\n",
    "* They are careful about distinguishing between social feedback changing _who_ participates versus _how_ participants participate\n",
    "\n",
    "Here is their methodology:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Tricks for Efficient Text Classification\n",
    "\n",
    "Joulin2016 come up with a classifier, `fasttext`, which can compete with deep learning classifiers in terms of accuracy while being many orders of magnitude faster.\n",
    "\n",
    "# Enriching Word Vectors with Subword Information\n",
    "\n",
    "Bojanowski2017 state that popular models that assign a distinct vector to each word for learning continous word representations trained on large unlabeled corpora ignore how words relate to one another. This is especially problematic for languages with large vocabularies and lots of rare words. They propose a new approach based on the skipgram model. Their method is fast, is able to work with words not appearing in training data and achieves state of the art performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation\n",
    "\n",
    "Blei2003 basically invent latent Dirichlet allocation - a generative probabilistic model for collections of discrete data like text corpora. LDA is a three-level hierarchical Bayesian model - each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, as well, modeled as an infinite mixture over an underlying set of topic probabilities. The topic probabilities explicitly represent the document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Spread of Misinformation on Social Media: 2016 US Presidential Election\n",
    "\n",
    "Social networks seem to have spurred fake news their velocity. Individual-level results show that low digital literacy among the elderly and partisanship/motivated reasoning are powerful mechanisms that may explain decisions interact with a \"fake\" story. \n",
    "\n",
    "In partisan communities of simarly-minded individuals, fake news is left unchallenged in part due to ranking algorithms filtering out dissenting voices.\n",
    "\n",
    "While there appears to be a consensus, the link between online echo-chambers and fake news is nuanced. Research has shown that social media news consumption is more diverse than offline news. Previous research by Pablo has shown that for most people social media has a depolarising effect, at least in terms of ideological stances.\n",
    "\n",
    "Citizens are now being exposed to all types of ideas – this includes conspiracy theories, hyper-partisanship and illiberal political opinions. I.e. it may not be that echo-chambers are the root of misinformation, but the opposite.\n",
    "\n",
    "Social media has shifted our news consumption by increasing exposure to information from weak ties - acquantainces/distant friends.\n",
    "\n",
    "False news stories often attract the attention of audiences not interested in politics, thus reducing spread of misinformation may reduce exposure to political news overall and lead to lower levels of political interest and civic engagement. On the other hand, increasing exposure to the \"other side\" of social media may increase the spread of misinformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat quality as a latent variable?\n",
    "\n",
    "Bayesian Spatial Following (Barberá2014): Can I treat quality as latent and inferred by interactions with community?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ravi (2014)\n",
    "\n",
    "Study question quality, considering questions on StackOverflow. Their definition of quality is based on analysis of interplay between views and upvotes (__why not answers and comments?__). They develop a binary classifier (__wouldn't continuous scale be better?__) using question content.\n",
    "\n",
    "Their models capture latent topical aspects of question at three tiers: 1) global model capturing topics for questions as a whole, 2) local model capturing topics at sentence level, 3) a global topic structure (Mallows) model which enforces structural constraints over sentence-level topics within a question. They are careful not to include features which are not inherent in new questions. Their classifier achieves accuracy of 72%, beating baselines such as number of views. Since their methods do not rely on domain-specific knowledge, they __believe__ models are applicable to other CQA settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Li (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ranking spans of text or passages (Voorhees and Tice, 2000; Yang et al., 2015; Rajpurkar et al., 2016; Agichtein et al., 2015; Ferrucci et al., 2010), and may even include synthesizing textual responses by gathering evidence from one or more sources (Nguyen et al., 2016b; Mitra et al., 2016b).§"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
